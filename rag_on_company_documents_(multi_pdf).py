# -*- coding: utf-8 -*-
"""RAG on Company Documents (Multi-PDF).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FVEHQU_qx5n75rrCEWfQO9AyH2xpbcez
"""

!pip install langchain faiss-cpu openai tiktoken sentence-transformers pypdf
!pip install langchain-community

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from transformers import pipeline
import glob

pdf_files = glob.glob("/content/*.pdf")
docs =[]
for pdf_file_path in pdf_files:
    loader = PyPDFLoader(pdf_file_path)
    docs.extend(loader.load())

#split and embed
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = splitter.split_documents(docs)

embed_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vector_db = FAISS.from_documents(splits, embed_model)

#query
query = "what is deep learning?"

retrieved_docs = vector_db.similarity_search(query, k=3)
context = "\n".join([d.page_content for d in retrieved_docs])

generator = pipeline("text2text-generation", model="google/flan-t5-base")

prompt = f"""

use me

context:{context}
question: {query}
answer:
"""

response = generator(prompt, max_length=300, temperature = 0.7)
print("Answer:", response[0]['generated_text'])

